ğŸ§  RAGnition V1 â€” Multimodal RAG System with LangChain + Groq
RAGnition V1 is a production-ready multimodal Retrieval-Augmented Generation (RAG) system that allows users to chat with an AI using uploaded documents (PDFs, images), online content (YouTube videos, URLs), or real-time web search.

Powered by:

ğŸ’¨ Groq's blazing-fast LLaMA/Mixtral models

ğŸ§  LangChain and ChromaDB for document understanding

ğŸ’» Streamlit for a clean chat UI

ğŸ” LangSmith for full tracing and debugging

ğŸš€ Features (V1 Highlights)
ğŸ§¾ Multimodal Inputs:

ğŸ“„ PDF documents

ğŸ–¼ï¸ Images (via OCR)

ğŸ“º YouTube video transcripts

ğŸŒ Webpage scraping

ğŸ” DuckDuckGo Search results

ğŸ” Smart Document Memory:

Cached via ChromaDB vectorstore

Auto-reuse of previously uploaded content

Fallback to LLM-only if no doc selected

âš¡ Powered by Groq:

Uses meta-llama/llama-4-scout-17b-16e-instruct

100x token throughput vs standard LLMs

ğŸ§  LangSmith Tracing (Optional):

Traced inputs, loaders, LLM outputs

Easy debugging and pipeline visibility

ğŸ“ Directory Structure
bash
Copy
Edit
RAGnition/
â”œâ”€â”€ main.py                   # Streamlit UI
â”œâ”€â”€ rag_pipeline.py           # RAG chain logic
â”œâ”€â”€ groq_llm.py               # Groq LLM init (with tracing)
â”œâ”€â”€ vector_store.py           # ChromaDB storage/reuse
â”‚
â”œâ”€â”€ loaders/                  # Modular input extractors
â”‚   â”œâ”€â”€ pdf_loader.py
â”‚   â”œâ”€â”€ image_ocr.py
â”‚   â”œâ”€â”€ youtube_loader.py
â”‚   â”œâ”€â”€ web_scraper.py
â”‚
â”œâ”€â”€ utils/                    # Extras (session, persistence)
â”‚   â””â”€â”€ persistence.py
â”‚
â”œâ”€â”€ chroma_db/                # Local vectorstores
â”œâ”€â”€ meta_db/                  # Document metadata
â”‚
â”œâ”€â”€ .env                      # Keys (Groq, LangSmith)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
ğŸ§ª Installation
1. Clone and Set Up Environment
bash
Copy
Edit
git clone https://github.com/SARVESHVARADKAR123/RAGnition.git
cd RAGnition
python -m venv venv
source venv/bin/activate        # macOS/Linux
venv\Scripts\activate           # Windows
2. Install Dependencies
bash
Copy
Edit
pip install -r requirements.txt
ğŸ” Environment Configuration
Create a .env file:

env
Copy
Edit
GROQ_API_KEY=your_groq_key_here
LANGSMITH_TRACING=true
LANGSMITH_API_KEY=your_langsmith_key
LANGSMITH_PROJECT=RAGnition
LANGSMITH_ENDPOINT=https://api.smith.langchain.com
â–¶ï¸ Run the App
bash
Copy
Edit
streamlit run main.py
Then visit: http://localhost:8501

âœ¨ How It Works
Choose an input (PDF, Image, URL, etc.)

Text is extracted and embedded using HuggingFace + ChromaDB

A Groq LLM retrieves top-relevant chunks and answers your query

Fallback to direct LLM response if no doc is used

ğŸ“Š Tracing with LangSmith (Built-in)
Every pipeline step is traced via @traceable:

Document loading

Embedding and vectorstore

Retrieval and LLM output

Displayed in LangSmith

âœ… No manual config required beyond .env

ğŸ§° Tech Stack
Tool	Purpose
LangChain	RAG logic, retrievers
ChromaDB	Vectorstore + chunk storage
HuggingFace	Embedding model
Groq	LLM inference (LLaMA/Mixtral)
Streamlit	Frontend UI
LangSmith	End-to-end observability

ğŸ“Œ Version Info
yaml
Copy
Edit
ğŸ§  RAGnition Version: v1.0.0
ğŸ” Multimodal: Yes
âš¡ Backend: Groq (LLM4)
ğŸ› ï¸ Framework: LangChain
ğŸ¯ Tracing: LangSmith enabled
ğŸ¤ Contributing
Have ideas, suggestions, or bugs?
Fork this repo, submit a PR, or reach out!